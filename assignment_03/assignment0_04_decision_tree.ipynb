{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_8wD0rxswQp"
      },
      "source": [
        "## assignment 04: Decision Tree construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGmZfrx5swQw"
      },
      "outputs": [],
      "source": [
        "# If working in colab, uncomment the following line\n",
        "# ! wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/basic_s20/homeworks_basic/assignment0_04_tree/tree.py -nc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTkszk-wswQx",
        "outputId": "2a6ee1c9-ac18-48ff-a84b-007ccbbed9bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.datasets import make_classification, make_regression, load_digits, load_boston\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkhwpjtswQy"
      },
      "source": [
        "Let's fix the `random_state` (a.k.a. random seed)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aOxdbFf4swQy"
      },
      "outputs": [],
      "source": [
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1xWJ5sTswQy"
      },
      "source": [
        "__Your ultimate task for today is to impement the `DecisionTree` class and use it to solve classification and regression problems.__\n",
        "\n",
        "__Specifications:__\n",
        "- The class inherits from `sklearn.BaseEstimator`;\n",
        "- Constructor is implemented for you. It has the following parameters:\n",
        "    * `max_depth` - maximum depth of the tree; `np.inf` by default\n",
        "    * `min_samples_split` - minimal number of samples in the leaf to make a split; `2` by default;\n",
        "    * `criterion` - criterion to select the best split; in classification one of `['gini', 'entropy']`, default `gini`; in regression `variance`;\n",
        "\n",
        "- `fit` method takes `X` (`numpy.array` of type `float` shaped `(n_objects, n_features)`) and `y` (`numpy.array` of type float shaped `(n_objects, 1)` in regression; `numpy.array` of type int shaped `(n_objects, 1)` with class labels in classification). It works inplace and fits the `DecisionTree` class instance to the provided data from scratch.\n",
        "\n",
        "- `predict` method takes `X` (`numpy.array` of type `float` shaped `(n_objects, n_features)`) and returns the predicted $\\hat{y}$ values. In classification it is a class label for every object (the most frequent in the leaf; if several classes meet this requirement select the one with the smallest class index). In regression it is the desired constant (e.g. mean value for `variance` criterion)\n",
        "\n",
        "- `predict_proba` method (works only for classification (`gini` or `entropy` criterion). It takes `X` (`numpy.array` of type `float` shaped `(n_objects, n_features)`) and returns the `numpy.array` of type `float` shaped `(n_objects, n_features)` with class probabilities for every object from `X`. Class $i$ probability equals the ratio of $i$ class objects that got in this node in the training set.\n",
        "\n",
        "    \n",
        "__Small recap:__\n",
        "\n",
        "To find the optimal split the following functional is evaluated:\n",
        "    \n",
        "$$G(j, t) = H(Q) - \\dfrac{|L|}{|Q|} H(L) - \\dfrac{|R|}{|Q|} H(R),$$\n",
        "    where $Q$ is the dataset from the current node, $L$ and $R$ are left and right subsets defined by the split $x^{(j)} < t$.\n",
        "\n",
        "\n",
        "\n",
        "1. Classification. Let $p_i$ be the probability of $i$ class in subset $X$ (ratio of the $i$ class objects in the dataset). The criterions are defined as:\n",
        "    \n",
        "    * `gini`: Gini impurity $$H(R) = 1 -\\sum_{i = 1}^K p_i^2$$\n",
        "    \n",
        "    * `entropy`: Entropy $$H(R) = -\\sum_{i = 1}^K p_i \\log(p_i)$$ (One might use the natural logarithm).\n",
        "    \n",
        "2. Regression. Let $y_l$ be the target value for the $R$, $\\mathbf{y} = (y_1, \\dots, y_N)$ â€“ all targets for the selected dataset $X$.\n",
        "    \n",
        "    * `variance`: $$H(R) = \\dfrac{1}{|R|} \\sum_{y_j \\in R}(y_j - \\text{mean}(\\mathbf{y}))^2$$\n",
        "    \n",
        "    * `mad_median`: $$H(R) = \\dfrac{1}{|R|} \\sum_{y_j \\in R}|y_j - \\text{median}(\\mathbf{y})|$$\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH2y8qkcswQ0"
      },
      "source": [
        "**Hints and comments**:\n",
        "\n",
        "* No need to deal with categorical features, they will not be present.\n",
        "* Siple greedy recursive procedure is enough. However, you can speed it up somehow (e.g. using percentiles).\n",
        "* Please, do not copy implementations available online. You are supposed to build very simple example of the Decision Tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yJRa0igswQ1"
      },
      "source": [
        "File `tree.py` is waiting for you. Implement all the needed methods in that file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1rHuqfGswQ2"
      },
      "source": [
        "### Check yourself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "ZO4xi8zGswQ2",
        "outputId": "404f900d-1242-493a-8248-7a248f5579f4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d60b4cb265e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmad_median\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'entropy' from 'tree' (/usr/local/lib/python3.7/dist-packages/tree/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from tree import entropy, gini, variance, mad_median, DecisionTree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EF03SJoswQ3"
      },
      "source": [
        "#### Simple check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVByhHX5swQ3"
      },
      "outputs": [],
      "source": [
        "X = np.ones((4, 5), dtype=float) * np.arange(4)[:, None]\n",
        "y = np.arange(4)[:, None] + np.asarray([0.2, -0.3, 0.1, 0.4])[:, None]\n",
        "class_estimator = DecisionTree(max_depth=10, criterion_name='gini')\n",
        "\n",
        "(X_l, y_l), (X_r, y_r) = class_estimator.make_split(1, 1., X, y)\n",
        "\n",
        "assert np.array_equal(X[:1], X_l)\n",
        "assert np.array_equal(X[1:], X_r)\n",
        "assert np.array_equal(y[:1], y_l)\n",
        "assert np.array_equal(y[1:], y_r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-sgjNrRswQ3"
      },
      "source": [
        "#### Classification problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZHHK83DswQ4"
      },
      "outputs": [],
      "source": [
        "digits_data = load_digits().data\n",
        "digits_target = load_digits().target[:, None] # to make the targets consistent with our model interfaces\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_target, test_size=0.2, random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPnwe9xiswQ4"
      },
      "outputs": [],
      "source": [
        "assert len(y_train.shape) == 2 and y_train.shape[0] == len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tGjgYjHswQ4"
      },
      "outputs": [],
      "source": [
        "class_estimator = DecisionTree(max_depth=10, criterion_name='gini')\n",
        "class_estimator.fit(X_train, y_train)\n",
        "ans = class_estimator.predict(X_test)\n",
        "accuracy_gini = accuracy_score(y_test, ans)\n",
        "print(accuracy_gini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_paLigzOswQ5"
      },
      "outputs": [],
      "source": [
        "reference = np.array([0.09027778, 0.09236111, 0.08333333, 0.09583333, 0.11944444,\n",
        "       0.13888889, 0.09930556, 0.09444444, 0.08055556, 0.10555556])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfTTxzq3swQ5"
      },
      "outputs": [],
      "source": [
        "class_estimator = DecisionTree(max_depth=10, criterion_name='entropy')\n",
        "class_estimator.fit(X_train, y_train)\n",
        "ans = class_estimator.predict(X_test)\n",
        "accuracy_entropy = accuracy_score(y_test, ans)\n",
        "print(accuracy_entropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxGWDUIgswQ5"
      },
      "outputs": [],
      "source": [
        "assert  0.84 < accuracy_gini < 0.9\n",
        "assert  0.86 < accuracy_entropy < 0.9\n",
        "assert np.sum(np.abs(class_estimator.predict_proba(X_test).mean(axis=0) - reference)) < 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8w_DX-DswQ5"
      },
      "source": [
        "Let's use 5-fold cross validation (`GridSearchCV`) to find optimal values for `max_depth` and `criterion` hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAnIGGWmswQ6"
      },
      "outputs": [],
      "source": [
        "param_grid = {'max_depth': range(3,11), 'criterion_name': ['gini', 'entropy']}\n",
        "gs = GridSearchCV(DecisionTree(), param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS-gQxd7swQ6"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "gs.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlMwXWivswQ6"
      },
      "outputs": [],
      "source": [
        "gs.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqzTolbZswQ6"
      },
      "outputs": [],
      "source": [
        "assert gs.best_params_['criterion_name'] == 'entropy'\n",
        "assert 6 < gs.best_params_['max_depth'] < 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk3XuDtrswQ7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "plt.title(\"The dependence of quality on the depth of the tree\")\n",
        "plt.plot(np.arange(3,11), gs.cv_results_['mean_test_score'][:8], label='Gini')\n",
        "plt.plot(np.arange(3,11), gs.cv_results_['mean_test_score'][8:], label='Entropy')\n",
        "plt.legend(fontsize=11, loc=1)\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jerePAFSswQ7"
      },
      "source": [
        "#### Regression problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAxN3qNNswQ7"
      },
      "outputs": [],
      "source": [
        "regr_data = load_boston().data\n",
        "regr_target = load_boston().target[:, None] # to make the targets consistent with our model interfaces\n",
        "RX_train, RX_test, Ry_train, Ry_test = train_test_split(regr_data, regr_target, test_size=0.2, random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73LBvge5swQ7"
      },
      "outputs": [],
      "source": [
        "regressor = DecisionTree(max_depth=10, criterion_name='mad_median')\n",
        "regressor.fit(RX_train, Ry_train)\n",
        "predictions_mad = regressor.predict(RX_test)\n",
        "mse_mad = mean_squared_error(Ry_test, predictions_mad)\n",
        "print(mse_mad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGIRaniOswQ8"
      },
      "outputs": [],
      "source": [
        "regressor = DecisionTree(max_depth=10, criterion_name='variance')\n",
        "regressor.fit(RX_train, Ry_train)\n",
        "predictions_mad = regressor.predict(RX_test)\n",
        "mse_var = mean_squared_error(Ry_test, predictions_mad)\n",
        "print(mse_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxIwU0FXswQ8"
      },
      "outputs": [],
      "source": [
        "assert 9 < mse_mad < 20\n",
        "assert 8 < mse_var < 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMFPmitGswQ8"
      },
      "outputs": [],
      "source": [
        "param_grid_R = {'max_depth': range(2,9), 'criterion_name': ['variance', 'mad_median']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS62d1E_swQ8"
      },
      "outputs": [],
      "source": [
        "gs_R = GridSearchCV(DecisionTree(), param_grid=param_grid_R, cv=5, scoring='neg_mean_squared_error', n_jobs=-2)\n",
        "gs_R.fit(RX_train, Ry_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNYF6w12swQ8"
      },
      "outputs": [],
      "source": [
        "gs_R.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJlX9tv8swQ9"
      },
      "outputs": [],
      "source": [
        "assert gs_R.best_params_['criterion_name'] == 'mad_median'\n",
        "assert 3 < gs_R.best_params_['max_depth'] < 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgH1qgLxswRA"
      },
      "outputs": [],
      "source": [
        "var_scores = gs_R.cv_results_['mean_test_score'][:7]\n",
        "mad_scores = gs_R.cv_results_['mean_test_score'][7:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyBxZNglswRA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "plt.title(\"The dependence of neg_mse on the depth of the tree\")\n",
        "plt.plot(np.arange(2,9), var_scores, label='variance')\n",
        "plt.plot(np.arange(2,9), mad_scores, label='mad_median')\n",
        "plt.legend(fontsize=11, loc=1)\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.ylabel('neg_mse')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "assignment0_04_decision_tree.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}